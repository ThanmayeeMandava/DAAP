


import luigi
import json
import os
import pandas as pd
from pymongo import MongoClient
from sqlalchemy import create_engine
import logging





# Setup basic logging
logging.basicConfig(level=logging.INFO)





class PrepareData(luigi.Task):
    # Parameter to specify the path of the JSON file to be processed
    filepath = luigi.Parameter()

    def output(self):
        # Specifies the output target with a modified filename
        return luigi.LocalTarget(self.filepath.replace('.json', '_prepared.json'))

    def run(self):
        # Log the start of the data preparation process
        logging.info(f"Starting to prepare data from {self.filepath}")

        # Load JSON data from the specified file
        with open(self.filepath, 'r', encoding='utf-8') as file:
            data = json.load(file)

        # Extract metadata and column names from JSON structure
        meta_data = data['meta']['view']
        columns = [col['name'] for col in meta_data['columns']]
        records = data['data']

        # Map records into a list of dictionaries using column names
        prepared_data = [dict(zip(columns, record)) for record in records]

        # Write the prepared data to the output file
        with self.output().open('w') as f:
            json.dump(prepared_data, f, ensure_ascii=False)

        # Log completion of data preparation
        logging.info("Data prepared and saved.")






class LoadDataToMongoDB(luigi.Task):
    # Parameter for the path of the prepared data file
    filepath = luigi.Parameter()

    def requires(self):
        # Specifies that this task depends on the completion of the PrepareData task
        return PrepareData(filepath=self.filepath)
class LoadDataToMongoDB(luigi.Task):
    filepath = luigi.Parameter()

    def requires(self):
        return PrepareData(filepath=self.filepath)

    def output(self):
        return luigi.LocalTarget(self.filepath.replace('.json', '_mongo_loaded.txt'))

    def run(self):
        logging.info("Loading data to MongoDB")

        try:
            client = MongoClient("mongodb://dap:dap@mongodb:27017/")
            db = client["Group_O"]
            collection = db["drugs_deaths_20234192"]

            with self.input().open('r') as file:
                data = json.load(file)

            collection.insert_many(data)
            client.close()

            with self.output().open('w') as f:
                f.write("Data loaded into MongoDB successfully.\n")

            logging.info("Data loaded into MongoDB successfully.")

        except Exception as e:
            logging.error(f"An error occurred while loading data to MongoDB: {e}")
            raise
    def output(self):
        # Defines the output file that confirms data loading to MongoDB
        return luigi.LocalTarget(self.filepath.replace('.json', '_mongo_loaded.txt'))

    def run(self):
        # Log the start of data loading into MongoDB
        logging.info("Loading data to MongoDB")

        # Connect to MongoDB using provided credentials (update with your credentials)
        client = MongoClient("mongodb://dap:dap@localhost:27017/")  
        db = client["Group_O"]  # Specify the database
        collection = db["drugs_deaths_20234192"]  # Specify the collection

        # Load the prepared data from the file
        with self.input().open('r') as file:
            data = json.load(file)

        # Insert data into the MongoDB collection
        collection.insert_many(data)
        
        # Close the MongoDB connection
        client.close()

        # Write a confirmation message to the output file
        with self.output().open('w') as f:
            f.write("Data loaded into MongoDB successfully.\n")

        # Log the successful data loading to MongoDB
        logging.info("Data loaded into MongoDB.")






class ExtractDataFromMongoDB(luigi.Task):
    def requires(self):
        # Specifies dependency on the LoadDataToMongoDB task
        return LoadDataToMongoDB(filepath='drug_deaths.json')

    def output(self):
        # Defines the output CSV file for the extracted data
        return luigi.LocalTarget('drug_deaths_raw.csv')

    def run(self):
        # Log the start of the data extraction process from MongoDB
        logging.info("Extracting data from MongoDB")

        # Connect to MongoDB using specified credentials (update with actual credentials)
        client = MongoClient("mongodb://dap:dap@localhost:27017/")
        db = client["Group_O"]  # Specify the database
        collection = db["drugs_deaths_20234192"]  # Specify the collection

        # Retrieve all records from the collection
        cursor = collection.find({})

        # Convert the MongoDB cursor to a DataFrame and drop the MongoDB-specific '_id' column
        df = pd.DataFrame(list(cursor))
        df.drop('_id', axis=1, inplace=True)

        # Save the DataFrame to CSV, excluding the index
        df.to_csv(self.output().path, index=False)

        # Close the MongoDB connection
        client.close()

        # Log the completion of data extraction
        logging.info("Data extraction completed.")






class TransformData(luigi.Task):
    def requires(self):
        # Specifies dependency on the ExtractDataFromMongoDB task
        return ExtractDataFromMongoDB()

    def output(self):
        # Defines the output CSV file for the transformed data
        return luigi.LocalTarget('drug_deaths_transformed.csv')

    def run(self):
        # Load the CSV data extracted from MongoDB
        df = pd.read_csv(self.input().path)

        # Remove unnecessary columns and handle errors gracefully
        df.drop(['id', 'position', 'sid', 'created_at', 'created_meta', 'updated_at', 'updated_meta', 'meta'], axis=1, errors='ignore', inplace=True)

        # Convert certain columns to numeric, coercing errors to NaN
        df['Median Number'] = pd.to_numeric(df['Median Number'], errors='coerce')
        df['MMWR Year'] = pd.to_numeric(df['MMWR Year'], errors='coerce')

        # Apply numeric conversion to multiple columns and coerce errors to NaN
        numeric_columns = ['Lower Bound', 'Upper Bound', 'Rolling 4-Week Mean', 'Rolling 4-Week Lower', 'Rolling 4-Week Upper']
        df[numeric_columns] = df[numeric_columns].apply(pd.to_numeric, errors='coerce')

        # Fill missing values in specific columns with the mean of their respective columns
        columns_with_nulls = ['Median Number', 'Lower Bound', 'Upper Bound', 'Rolling 4-Week Mean', 'Rolling 4-Week Lower', 'Rolling 4-Week Upper']
        for column in columns_with_nulls:
            mean_value = df[column].mean()
            df[column].fillna(mean_value, inplace=True)
        
        # Save the transformed data to a CSV file without the index
        df.to_csv(self.output().path, index=False)

        # Log the completion of data transformation
        logging.info("Data transformation completed and saved to CSV.")






class LoadDataToPostgres(luigi.Task):
    def requires(self):
        # Specifies dependency on the TransformData task
        return TransformData()

    def output(self):
        # Defines the output file that indicates successful data loading to PostgreSQL
        return luigi.LocalTarget('drug_deaths_postgres_done.txt')

    def run(self):
        # Log the start of the data loading process into PostgreSQL
        logging.info("Loading data into PostgreSQL")

        # Establish connection to PostgreSQL using provided credentials (update with actual credentials)
        engine = create_engine('postgresql://postgres:root@localhost:5432/Group_O')

        # Load the CSV data transformed in the previous task
        df = pd.read_csv(self.input().path)

        # Load data into PostgreSQL, replacing existing data if it exists
        df.to_sql('drugs_deaths_20234192', engine, if_exists='replace', index=False)

        # Dispose of the database engine connection
        engine.dispose()

        # Write a confirmation message to the output file
        with self.output().open('w') as f:
            f.write("Data loaded into PostgreSQL successfully.\n")

        # Log the successful loading of data into PostgreSQL
        logging.info("Data loaded into PostgreSQL.")






if __name__ == '__main__':
    luigi.build([LoadDataToPostgres()], local_scheduler=False)





def fetch_data_from_postgres(username, password, hostname, port, database, table_name):
    
    # Create the database engine
    engine = create_engine(f'postgresql://{username}:{password}@{hostname}:{port}/{database}')

    # SQL query to select all data from the table
    query = f'SELECT * FROM public."{table_name}"'

    # Execute the query and return a DataFrame
    df = pd.read_sql_query(query, con=engine)
    
    return df





if __name__ == "__main__":
    # Database parameters
    username = "postgres"  # Replace with your username
    password = "root"      # Replace with your password
    hostname = "127.0.0.1" # Replace with your database host
    port = "5432"          # Replace with your database port
    database_name = "Group_O" # Replace with your database name
    table_name = "drugs_deaths_20234192" # Replace with your table name





# Fetch the data
df = fetch_data_from_postgres(username, password, hostname, port, database_name, table_name)
# Display the first few rows of the DataFrame
print(df.head()) 





df.head()


 df.info()


 df.describe()









































import psycopg2
import matplotlib.pyplot as plt
import seaborn as sns


# Calculate yearly data for each outcome
yearly_data = df.groupby(['MMWR Year', 'Outcome']).agg({'Median Number': 'sum'}).unstack()

# Plotting the year-to-year trends
plt.figure(figsize=(10, 6))
for outcome in yearly_data.columns.levels[1]:
    plt.plot(yearly_data.index, yearly_data[('Median Number', outcome)], marker='o', label=outcome)

plt.title('Year-to-Year Trends in Deaths by Outcome')
plt.xlabel('Year')
plt.ylabel('Total Estimated Deaths')
plt.xticks(yearly_data.index)  # Ensure all years are included as x-ticks
plt.legend(title='Outcome')
plt.grid(True)
plt.show()


import matplotlib.pyplot as plt
import seaborn as sns

# Set the aesthetic style of the plots
sns.set_style("whitegrid")

# Filter data for plotting
plot_data = df.groupby(['Week Ending Date', 'Outcome']).agg({'Median Number': 'sum'}).unstack()

# Plotting the data
plt.figure(figsize=(14, 7))
for outcome in plot_data.columns.levels[1]:
    plt.plot(plot_data.index, plot_data[('Median Number', outcome)], label=outcome)

plt.title('Trends in Deaths Over Time by Outcome')
plt.xlabel('Date')
plt.ylabel('Total Estimated Deaths')
plt.legend(title='Outcome')
plt.show()


import matplotlib.pyplot as plt

# Group the data by MMWR Year and calculate the median number of deaths
yearly_data = df.groupby('MMWR Year')['Median Number'].median()

# Plotting
plt.figure(figsize=(10, 6))

plt.bar(yearly_data.index, yearly_data.values)

plt.title('Median Number of Deaths by MMWR Year')
plt.xlabel('MMWR Year')
plt.ylabel('Median Number of Deaths')
plt.grid(axis='y')
plt.tight_layout()
plt.show()


import pandas as pd
import plotly.express as px

# Sample DataFrame creation (replace with your actual DataFrame loading)
data = {
    'Outcome': ['Drug Overdose', 'Suicide', 'Transport Accident']
}
df = pd.DataFrame(data)

# Calculate the distribution of outcomes
outcome_distribution = df['Outcome'].value_counts().reset_index()
outcome_distribution.columns = ['Outcome', 'count']  # Rename columns for clarity

# Create a pie chart to visualize the outcome distribution
fig2 = px.pie(outcome_distribution, values='count', names='Outcome', title='Outcome Distribution')
fig2.show()



# Filter data for Drug Overdose only
drug_overdose_data = df[df['Outcome'] == 'Drug Overdose']

# Yearly trend for Drug Overdose
yearly_drug_overdose = drug_overdose_data.groupby('MMWR Year')['Median Number'].sum()

# Seasonal trend for Drug Overdose
seasonal_drug_overdose = drug_overdose_data.groupby('MMWR Week')['Median Number'].sum()

# Plotting the trends
fig, ax = plt.subplots(2, 1, figsize=(14, 12))

# Yearly trend plot
ax[0].plot(yearly_drug_overdose.index, yearly_drug_overdose.values, marker='o', linestyle='-', color='blue')
ax[0].set_title('Yearly Trends in Drug Overdose Deaths')
ax[0].set_xlabel('Year')
ax[0].set_ylabel('Total Estimated Drug Overdose Deaths')

# Seasonal trend plot
ax[1].plot(seasonal_drug_overdose.index, seasonal_drug_overdose.values, linestyle='-', color='green')
ax[1].set_title('Seasonal Patterns in Drug Overdose Deaths by MMWR Week')
ax[1].set_xlabel('Week of the Year')
ax[1].set_ylabel('Total Estimated Drug Overdose Deaths')
ax[1].set_xticks(range(1, 54, 4))  # Show every 4th week for clarity

plt.tight_layout()
plt.show()


# Average annual drug overdose deaths by state
state_drug_overdose = drug_overdose_data.groupby(['State', 'MMWR Year'])['Median Number'].sum().groupby('State').mean()

# Plotting state-specific drug overdose deaths
plt.figure(figsize=(14, 8))
state_drug_overdose.sort_values(ascending=False).plot(kind='bar', color='maroon')
plt.title('Average Annual Drug Overdose Deaths by State')
plt.xlabel('State')
plt.ylabel('Average Annual Deaths')
plt.xticks(rotation=90)  # Rotate state labels for better visibility
plt.show()



